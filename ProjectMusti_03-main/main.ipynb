{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Classifiers\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import randint\n",
    "import os\n",
    "import tarfile\n",
    "import cv2\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set numpy's random-state to 42 to make this notebook's output stable across runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reload data** decides if a new dataframe has to be created. \\\n",
    "Default is False, but will be set to True if no dataframe exists yet.\\\n",
    "Can be set to True to force the program to overwrite an existing dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RELOAD_DATA = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function 'target_value'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_value(val):\n",
    "    if val == 'aanwezig':\n",
    "        return 2\n",
    "    if val == 'buiten':\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if directory 'model' exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('./model/'):\n",
    "    os.mkdir('./model/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if a dataframe exists, and create a new one if this is not the case.\n",
    "Else load the existing dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tar...\n",
      "Extracting tar Done!\n",
      "Creating dataframe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ayari\\AppData\\Local\\Temp\\ipykernel_17908\\794651969.py:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  musti = musti.append(temp_df, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isfile('./model/dataframe.sav'):\n",
    "    RELOAD_DATA = True # When there is not yet a dataframe, create one\n",
    "\n",
    "if RELOAD_DATA: # Check whether there needs to be created a new dataframe\n",
    "    #Extract when not already extracted\n",
    "    if not os.path.isdir('./data/classificatie'):\n",
    "        if not os.path.isfile('./data/classificatie.tar'):\n",
    "            raise Exception('Classificatie.tar not fount')\n",
    "\n",
    "        print('Extracting tar...')\n",
    "        tar = tarfile.open('./data/classificatie.tar')\n",
    "        tar.extractall('./data/')\n",
    "        tar.close()\n",
    "        print('Extracting tar Done!')\n",
    "\n",
    "    if not os.path.isdir('./data/classificatie'):\n",
    "        raise Exception('Extracted files not found')\n",
    "\n",
    "\n",
    "    # Get grayscale values from pictures\n",
    "    print('Creating dataframe')\n",
    "    samples = []\n",
    "    sample_counter = 0\n",
    "    musti = pd.DataFrame()\n",
    "\n",
    "    for folder in os.listdir('./data/classificatie/'):\n",
    "        for file in os.listdir(f'./data/classificatie/{folder}'):\n",
    "            img = cv2.imread(f'./data/classificatie/{folder}/{file}', 0)\n",
    "            img = cv2.normalize(img,np.zeros(img.shape), 0, 1000, cv2.NORM_MINMAX)\n",
    "\n",
    "            # add them to a dataframe\n",
    "            imgd = dict()\n",
    "            imgd['target'] = target_value(folder)\n",
    "            c = 0\n",
    "            for i in img.flatten():\n",
    "                c += 1\n",
    "                imgd[f'p{c}'] = i\n",
    "            samples.append(imgd)\n",
    "            sample_counter+=1\n",
    "            #print(file)\n",
    "\n",
    "            if sample_counter % 200==0:\n",
    "                temp_df = pd.DataFrame.from_dict(samples)\n",
    "                musti = musti.append(temp_df, ignore_index=True)\n",
    "                samples = []\n",
    "    temp_df = pd.DataFrame.from_dict(samples)\n",
    "    musti = musti.append(temp_df, ignore_index=True)\n",
    "    samples = []\n",
    "\n",
    "    print('Saving DataFrame')\n",
    "    \n",
    "    pickle.dump(musti, open('./model/dataframe.sav', 'wb'))\n",
    "else:\n",
    "    print('Loading DataFrame')\n",
    "    musti = pickle.load(open('./model/dataframe.sav', 'rb'))\n",
    "\n",
    "print('DataFrame Loaded')\n",
    "print(musti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4107142857142857 0\n",
      "0.5758354755784062 1\n",
      "0.0 2\n",
      "165 165 165\n"
     ]
    }
   ],
   "source": [
    "# smallest_dataset_len = min(len(musti[musti.target == 2]), len(musti[musti.target == 1]), len(musti[musti.target == 0]))\n",
    "# for i in range(3):\n",
    "#     frac = 1 - smallest_dataset_len / len(musti[musti.target == i])\n",
    "#     print(frac, i)\n",
    "#     musti = musti.drop(musti.query(f'target == {i}').sample(frac=frac).index)\n",
    "\n",
    "# print(len(musti[musti.target == 2]), len(musti[musti.target == 1]), len(musti[musti.target == 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set Shape: (396, 225280)\n"
     ]
    }
   ],
   "source": [
    "X, y = musti.drop('target', axis=1), musti['target']\n",
    "y = y.astype(np.uint8)  # less RAM space\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(f'Training set Shape: {X_train.shape}')\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and fit the chosen model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting model\n",
      "GridSearchCV(cv=3, estimator=RandomForestClassifier(),\n",
      "             param_grid=[{'max_features': [2, 4, 8],\n",
      "                          'n_estimators': [10, 100, 200],\n",
      "                          'random_state': [42]}],\n",
      "             verbose=2)\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier()\n",
    "print('fitting model')\n",
    "\n",
    "#optimal params found with GridSearchCV for RandomForestClassifier\n",
    "param_grid = [\n",
    "    {'n_estimators': [135], \n",
    "     'max_features': [18],\n",
    "     'max_depth': [36],\n",
    "     'min_samples_split': [2],\n",
    "     'min_samples_leaf':[1],\n",
    "     'random_state': [42]},\n",
    "    ]\n",
    "\n",
    "gridsearch = GridSearchCV(model, param_grid, cv=3, verbose=2)\n",
    "print(gridsearch)\n",
    "gridsearch.fit(X_train, y_train)\n",
    "\n",
    "print(gridsearch.best_params_,gridsearch.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the chosen model and print the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = cross_val_score(model, X_test, y_test, cv=3)\n",
    "# print(f'\\t{a}')\n",
    "# print(f'\\tmean: {np.mean(a)}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5121bd3a35215f255f04af5486badf7493b805d644bc99080ec709e2d9bd47d9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('Python3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0b2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
