{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0dQOWD9TqIR"
      },
      "source": [
        "Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mEJp8OjMTqIU"
      },
      "outputs": [],
      "source": [
        "# Python ≥3.5 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# Scikit-Learn ≥0.20 is required\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "#Classifiers\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import tarfile\n",
        "import cv2\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtyr0sKMTqIW"
      },
      "source": [
        "Set numpy's random-state to 42 to make this notebook's output stable across runs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rpqu98BCTqIY"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIXGY80XTqIZ"
      },
      "source": [
        "**Reload data** decides if a new dataframe has to be created. \\\n",
        "Default is False, but will be set to True if no dataframe exists yet.\\\n",
        "Can be set to True to force the program to overwrite an existing dataframe.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QnU0FIDKTqIa"
      },
      "outputs": [],
      "source": [
        "RELOAD_DATA = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRSl50i1TqIb"
      },
      "source": [
        "Helper function 'target_value'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2WtbIC_qTqIb"
      },
      "outputs": [],
      "source": [
        "def target_value(val):\n",
        "    if val == 'aanwezig':\n",
        "        return 2\n",
        "    if val == 'buiten':\n",
        "        return 1\n",
        "    return 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0QlB1-mTqIc"
      },
      "source": [
        "Check if directory 'model' exists."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Fn3yHm7TqIe"
      },
      "outputs": [],
      "source": [
        "if not os.path.isdir('./model/'):\n",
        "    os.mkdir('./model/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MESU_cc8TqIe"
      },
      "source": [
        "Check if a dataframe exists, and create a new one if this is not the case.\n",
        "Else load the existing dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ht2cEOggTqIf",
        "outputId": "82587057-5888-46bd-b8ef-bea1a19b4dec"
      },
      "outputs": [],
      "source": [
        "if not os.path.isfile('./model/dataframe.sav'):\n",
        "    RELOAD_DATA = True # When there is not yet a dataframe, create one\n",
        "\n",
        "if RELOAD_DATA: # Check whether there needs to be created a new dataframe\n",
        "    #Extract when not already extracted\n",
        "    if not os.path.isdir('./data/classificatie'):\n",
        "        if not os.path.isfile('./data/classificatie.tar'):\n",
        "            raise Exception('classificatie.tar not fount')\n",
        "\n",
        "        print('Extracting tar...')\n",
        "        tar = tarfile.open('./data/classificatie.tar')\n",
        "        tar.extractall('./data/')\n",
        "        tar.close()\n",
        "        print('Extracting tar Done!')\n",
        "\n",
        "    if not os.path.isdir('./classificatie'):\n",
        "        raise Exception('Extracted files not found')\n",
        "\n",
        "\n",
        "    # Get grayscale values from pictures\n",
        "    print('Creating dataframe')\n",
        "    samples = []\n",
        "    sample_counter = 0\n",
        "    musti = pd.DataFrame()\n",
        "\n",
        "    for folder in os.listdir('./classificatie/'):\n",
        "        for file in os.listdir(f'./classificatie/{folder}'):\n",
        "            img = cv2.imread(f'./classificatie/{folder}/{file}', 0)\n",
        "            img = cv2.normalize(img,np.zeros((640, 352)), 0, 1000, cv2.NORM_MINMAX)\n",
        "            # add them to a dataframe\n",
        "            imgd = dict()\n",
        "            imgd['target'] = target_value(folder)\n",
        "            c = 0\n",
        "            for i in img.flatten():\n",
        "                c += 1\n",
        "                imgd[f'p{c}'] = i\n",
        "            samples.append(imgd)\n",
        "            sample_counter+=1\n",
        "\n",
        "            if sample_counter % 200==0:\n",
        "                temp_df = pd.DataFrame.from_dict(samples)\n",
        "                musti = musti.append(temp_df, ignore_index=True)\n",
        "                samples = []\n",
        "    temp_df = pd.DataFrame.from_dict(samples)\n",
        "    musti = musti.append(temp_df, ignore_index=True)\n",
        "    samples = []\n",
        "\n",
        "    print('Saving DataFrame')\n",
        "    \n",
        "    pickle.dump(musti, open('./model/dataframe.sav', 'wb'))\n",
        "else:\n",
        "    print('Loading DataFrame')\n",
        "    musti = pickle.load(open('./model/dataframe.sav', 'rb'))\n",
        "\n",
        "print('DataFrame Loaded')\n",
        "print(musti)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9forvA0NTqIh"
      },
      "outputs": [],
      "source": [
        "smallest_dataset_len = min(len(musti[musti.target == 2]), len(musti[musti.target == 1]), len(musti[musti.target == 0]))\n",
        "for i in range(3):\n",
        "    frac = 1 - smallest_dataset_len / len(musti[musti.target == i])\n",
        "    print(frac, i)\n",
        "    musti = musti.drop(musti.query(f'target == {i}').sample(frac=frac).index)\n",
        "\n",
        "print(len(musti[musti.target == 2]), len(musti[musti.target == 1]), len(musti[musti.target == 0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vws9NWd8TqIh"
      },
      "source": [
        "Create training and test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVDpxc1WTqIh",
        "outputId": "f73b6ec9-5f3e-4dd7-a57e-05c3ea57f254"
      },
      "outputs": [],
      "source": [
        "X, y = musti.drop('target', axis=1), musti['target']\n",
        "y = y.astype(np.uint8)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H58RDdRPTqIi"
      },
      "source": [
        "Create and fit the chosen model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rh1iEKNvTqIi",
        "outputId": "9081dee9-063b-4537-c072-2104cfd83f08"
      },
      "outputs": [],
      "source": [
        "model = RandomForestClassifier(n_estimators= 185, max_features= 11, random_state= 42)\n",
        "print('fitting model')\n",
        "\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "pickle.dump(model, open('./model/model.sav', 'wb'))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "main.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "59dc825e95d878a23b222291e3b0db63d685ad1997f3d85f19cae6cf6a4e66ac"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('Python3')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
